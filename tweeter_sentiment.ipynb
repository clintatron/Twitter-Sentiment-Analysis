{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs from sample Twitter data to test sentiment analysis. First loads data from [Twitter's API](https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline). The below cell will import this data as a variable `SAMPLE_TWEETS` from the provided _module_ file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import from uw_ischool_sample file in the `data/` package (folder)\n",
    "from data.uw_ischool_sample import SAMPLE_TWEETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints out the first three elements from the `SAMPLE_TWEETS` list to see what information can be found. The most relevant value is the `\"text\"` of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'created_at': 'Mon Oct 10 18:39:51 +0000 2016',\n",
       "  'entities': {'hashtags': [{'indices': [20, 41],\n",
       "     'text': 'IndigenousPeoplesDay'}]},\n",
       "  'retweet_count': 9,\n",
       "  'text': 'RT @UWAPress: Happy #IndigenousPeoplesDay https://t.co/YmU9e9lj7v',\n",
       "  'user': {'screen_name': 'UW_iSchool'}},\n",
       " {'created_at': 'Mon Oct 10 18:00:00 +0000 2016',\n",
       "  'entities': {'hashtags': [{'indices': [16, 29], 'text': 'IdealistFair'}]},\n",
       "  'retweet_count': 0,\n",
       "  'text': \"We'll be at the #IdealistFair this evening on the Seattle U. campus. Come and learn about our graduate programs: https://t.co/et1HrQshmr\",\n",
       "  'user': {'screen_name': 'UW_iSchool'}},\n",
       " {'created_at': 'Mon Oct 10 15:10:36 +0000 2016',\n",
       "  'entities': {'hashtags': []},\n",
       "  'retweet_count': 1,\n",
       "  'text': 'RT @iYouthUW: iYouth Tips for 1st\\xa0Years https://t.co/K4SCIEhJ8k https://t.co/p4lbC6Jb5o',\n",
       "  'user': {'screen_name': 'UW_iSchool'}}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_TWEETS[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second piece of data for this analysis is a set of **word-sentiments**&mdash;a list of English-language words and what emotions (e.g., \"joy\", \"anger\") [are associated with them](http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data.sentiments_nrc import SENTIMENTS\n",
    "from data.sentiments_nrc import EMOTIONS\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines a function that take a tweet's text (a string) and splits it up into a list of individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tweet_filter(stringtext):\n",
    "    \"\"\" Function converting text into lowercase and filtering out words with length less than 1 \"\"\"\n",
    "    wordtext = re.split('\\W+', stringtext.lower()) \n",
    "    lengthywords = [word for word in wordtext if len(word) > 1]\n",
    "    return lengthywords\n",
    "\n",
    "wordlist = tweet_filter(\"Amazingly, I prefer a #rainy day to #sunshine.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines a function that **filters** a list of the words to get only those words that contain a specific emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emotional_filter(wordtext,emotion):\n",
    "    \"\"\" Function Filtering only words with emotion \"\"\"\n",
    "    default=-1\n",
    "    emotion_filterer = [word for word in wordtext if SENTIMENTS.get(word,default) != -1 if SENTIMENTS.get(word,default).get(emotion,default) == 1 ]\n",
    "    return(emotion_filterer)\n",
    "\n",
    "emotional_filter(\"Amazingly, I prefer a #rainy day to #sunshine.\", 'positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines a function that determines which words from a list have _each_ emotion (i.e., the \"emotional\" words). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def emotional_words(wordtext):\n",
    "    \"\"\" Funtion finds words with emotion from a given list of EMOTIONS \"\"\"\n",
    "    dictionary_emowords = {}\n",
    "    for emotion in EMOTIONS:\n",
    "        emotion_words = emotional_filter(wordtext,emotion)\n",
    "        dictionary_emowords[emotion] = emotion_words \n",
    "    return(dictionary_emowords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines a function that gets a list of the \"most common\" words in a list: that is a new list containing each word in the original list, in descending order by how many times that word appears in the orignal list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def common_words(wordtext):\n",
    "    \"\"\" Evaluates the common words and their frequency in a list \"\"\"\n",
    "\n",
    "    lowercase_word = [word.lower() for word in wordtext] \n",
    "    dictionary_word_frequency = {word: 0 for word in lowercase_word} \n",
    "   \n",
    "    for word in lowercase_word:\n",
    "        dictionary_word_frequency[word]+=1\n",
    "    words_frequency_list = sorted(dictionary_word_frequency.items(), key=lambda n: n[1], reverse=True)\n",
    "\n",
    "    for i in range(len(words_frequency_list)):\n",
    "        words_frequency_list[i] = words_frequency_list[i][0]\n",
    "        \n",
    "    return(words_frequency_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines a function (e.g., `analyze_tweets()`) that takes as an argument a **list** of tweet data (with the same structure as the imported `SAMPLE_TWEETS` variable), and _returns_ the data of interest to display in a table like the one at the very top of the notebook. Produces the following information **for each emotion**:\n",
    "\n",
    "1. The percentage of words _across all tweets_ that have that emotion\n",
    "2. The most common words _across all tweets_ that have that emotion (in order!)\n",
    "3. The most common **hashtags** _across all tweets_ associated with that emotion (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_tweets(list_tweets):\n",
    "    \"\"\" For all of the emotions in EMOTION, this function calculates percentage of words having emotion,\n",
    "        high frequency common words having emotion and the high frequency common hashtags in accordance \n",
    "        to that emotion \"\"\"\n",
    "    \n",
    "    total=0\n",
    "    total_emotion=0\n",
    "    list_hashtags = []\n",
    "    dictionary_emotionalwordsnum = dict(zip(EMOTIONS,[0]*10))         \n",
    "    \n",
    "    for i in range(len(list_tweets)):\n",
    "        list_tweetwords = []\n",
    "        dictionary_emowordings = {}\n",
    "\n",
    "        tweettext = list_tweets[i]['text']\n",
    "        list_tweetwords =  tweet_filter(tweettext)\n",
    "        list_tweets[i]['words'] = list_tweetwords \n",
    "        dictionary_emowordings = emotional_words(list_tweetwords)\n",
    "        list_tweets[i]['emotional_words'] = dictionary_emowordings\n",
    "        \n",
    "    \n",
    "    for tdata in list_tweets:\n",
    "        total += reduce(lambda x,y: x+1, tdata['words'], 0)\n",
    "        dictionary_emotionalwordsnum ['positive'] += reduce(lambda x,y: x+1, tdata['emotional_words']['positive'], 0)\n",
    "\n",
    "        dictionary_emotionalwordsnum ['negative'] += reduce(lambda x,y: x+1, tdata['emotional_words']['negative'], 0)\n",
    "        \n",
    "        dictionary_emotionalwordsnum ['anger'] += reduce(lambda x,y: x+1, tdata['emotional_words']['anger'], 0)\n",
    "        \n",
    "        dictionary_emotionalwordsnum ['anticipation'] += reduce(lambda x,y: x+1, tdata['emotional_words']['anticipation'], 0)\n",
    "        \n",
    "        dictionary_emotionalwordsnum ['disgust'] += reduce(lambda x,y: x+1, tdata['emotional_words']['disgust'], 0)\n",
    "        \n",
    "        dictionary_emotionalwordsnum ['fear'] += reduce(lambda x,y: x+1, tdata['emotional_words']['fear'], 0)\n",
    "        \n",
    "        dictionary_emotionalwordsnum ['joy'] += reduce(lambda x,y: x+1, tdata['emotional_words']['joy'], 0)\n",
    "        \n",
    "        dictionary_emotionalwordsnum ['sadness'] += reduce(lambda x,y: x+1, tdata['emotional_words']['sadness'], 0)\n",
    "        \n",
    "        dictionary_emotionalwordsnum ['surprise'] += reduce(lambda x,y: x+1, tdata['emotional_words']['surprise'], 0)\n",
    "        \n",
    "        dictionary_emotionalwordsnum ['trust'] += reduce(lambda x,y: x+1, tdata['emotional_words']['trust'], 0)\n",
    "   \n",
    "    dictionary_emotionalwordsnum_sorted = sorted(dictionary_emotionalwordsnum.items(), key=lambda x: x[1], reverse = True)\n",
    "    \n",
    "    dictionary_emotionalhastag = hashtags_for_emotion(list_tweets)\n",
    "    \n",
    "    return(total,dictionary_emotionalwordsnum_sorted,dictionary_emotionalhastag)\n",
    "\n",
    "def hashtags_for_emotion(tdata):\n",
    "    \"\"\" Finds hashtags for each emotion \"\"\"\n",
    "\n",
    "    initial_list = [[] for i in range(1,11)]\n",
    "    dictionary_emotionalhastag = dict(zip(EMOTIONS,initial_list))\n",
    "    for tweet in tdata:\n",
    "        tweetwords = tweet_filter(tweet['text'])\n",
    "        for emotion in EMOTIONS:\n",
    "            if emotional_filter(tweetwords,emotion):\n",
    "                if tweet['entities']['hashtags']:\n",
    "                    for i in range(len(tweet['entities']['hashtags'])):\n",
    "                        hashtag = tweet['entities']['hashtags'][i]['text']\n",
    "                        dictionary_emotionalhastag[emotion].append(hashtag)\n",
    "    return(dictionary_emotionalhastag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays information as a printed table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'twitter_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e878bf98c2c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0:<15s} {1:5.2f}%       {2:<30s}   {3:30s}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpercentage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcom_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcom_hashtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdisplay_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwitter_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictionary_emotionalwordsnum_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictionary_emotionalhastag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'twitter_data' is not defined"
     ]
    }
   ],
   "source": [
    "def display_stats(tdata,total,dictionary_emotionalwordsnum_sorted,dictionary_emotionalhastag):\n",
    "    \"\"\" Prints each emotion and its attributes \"\"\"\n",
    "\n",
    "    tweets_textlist = [tdata[i]['text'] for i in range(len(tdata))]\n",
    "    tweettext = tweet_filter (reduce(lambda x,y: x+y,tweets_textlist))\n",
    "\n",
    "    print(\"{0:<15s}  {1:<5s}  {2:<30s}   {3:<30s}\".format('EMOTION','% of WORDS','EXAMPLE WORDS','HASHTAGS'))\n",
    "\n",
    "    for emotion in dictionary_emotionalwordsnum_sorted:\n",
    "        percentage = (emotion[1]/total)*100\n",
    "        com_words = ','.join(common_words(emotional_filter(tweettext,emotion[0]))[:3])\n",
    "        com_hashtags_wordlist = common_words(dictionary_emotionalhastag[emotion[0]])[:3]\n",
    "        com_hashtags = ','.join(['#'+tag for tag in com_hashtags_wordlist])\n",
    "        print(\"{0:<15s} {1:5.2f}%       {2:<30s}   {3:30s}\".format(emotion[0],percentage,com_words,com_hashtags))\n",
    "\n",
    "display_stats(twitter_data,total,dictionary_emotionalwordsnum_sorted,dictionary_emotionalhastag)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling Live Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines function that takes in a Twitter username as an argument and then returns a list of dictionaries representing the tweets made by that user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_twitter_data(screen_name,count=200):\n",
    "  \"\"\" Gets live data from twitter for a particular twitter screen name and number of tweets specified \"\"\"\n",
    "\n",
    "  parameters={'screen_name':screen_name,'count':count}\n",
    "  myreq = requests.get(url='https://api.twitter.com/1.1/statuses/clintatron',params=parameters)\n",
    "  tweetdata = json.loads(myreq.text)\n",
    "  return tweetdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines \"main\" function that will prompt the user for a Twitter username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the screen name: @clintatron\n",
      "Enter number of tweets to be Scraped: 20\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a9aa79eed7f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter number of tweets to be Scraped: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtwitter_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_twitter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictionary_emotionalwordsnum_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictionary_emotionalhastag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwitter_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-b371bb1969f0>\u001b[0m in \u001b[0;36mdownload_twitter_data\u001b[0;34m(screen_name, count)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'screen_name'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmyreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'https://api.twitter.com/1.1/statuses/clintatron'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mtweetdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtweetdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clintatron/anaconda/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clintatron/anaconda/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/clintatron/anaconda/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    from data.uw_ischool_sample import SAMPLE_TWEETS\n",
    "    from data.sentiments_nrc import SENTIMENTS\n",
    "    from data.sentiments_nrc import EMOTIONS\n",
    "    from functools import reduce\n",
    "    import re\n",
    "    import json\n",
    "    import requests\n",
    "\n",
    "    screen_name = input('Enter the screen name: ')\n",
    "\n",
    "    \n",
    "    if screen_name == 'SAMPLE':\n",
    "        twitter_data = SAMPLE_TWEETS\n",
    "    else:\n",
    "        count = input('Enter number of tweets to be Scraped: ')\n",
    "        twitter_data = download_twitter_data(screen_name,count)\n",
    "\n",
    "    total,dictionary_emotionalwordsnum_sorted,dictionary_emotionalhastag = analyze_tweets(twitter_data)\n",
    "\n",
    "    display_stats(twitter_data,total,dictionary_emotionalwordsnum_sorted,dictionary_emotionalhastag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-96b81e570a90>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-96b81e570a90>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    20\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
